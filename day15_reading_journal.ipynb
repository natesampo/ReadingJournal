{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 15 Reading Journal\n",
    "\n",
    "This journal includes several required exercises, but it is meant to encourage active reading more generally.  You should use the journal to take detailed notes, catalog questions, and explore the content from Think Python deeply.\n",
    "\n",
    "Reading: Think Python Appendix B (through B.2)\n",
    "\n",
    "**Due: Thursday, March 23 at 12 noon**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Appendix B](http://www.greenteapress.com/thinkpython2/html/thinkpython2022.html)\n",
    "\n",
    "You only need to read as far as section B.2 (inclusive), but feel free to go further and try more exercises if you are interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "In Big O notation, for loops are typically what constitutes adding a degree to a term. For example, a single for loop would be O(n) notation, while a nested for loop would be O(n<sup>2</sup>).\n",
    "\n",
    "I'm assuming this applies to all things that are similar to for loops, including list comprehensions and working with dictionaries. How does dictionary search work? Does it search through every key in the dictionary, or does it store an internal hash table that is callable with keys, or some other method? What is the speed of that?\n",
    "\n",
    "O(n<sup>x</sup>) complexity is normally best at low x values, however some algorithms work faster than others, even if they are at higher x values if the n value remains low. The n point at which the lower x value becomes better is called the crossover point. Despite the fact that large x values can run faster, programs should typically be kept at as low x value as possible, because that way any increase in n won't cause a gigantic increase in run time and complexity.\n",
    "\n",
    "Adding elements to the end of lists takes O(1) time for each element, and O(n) time for n number of elements, so linear complexity.\n",
    "\n",
    "Removing elements from the end of lists is constant time.\n",
    "\n",
    "Sorting is logarithmic time. I wonder why? Probably because it takes lots of time at first and less time towards the end. Most algorithms for sorting look like trees, with the final step typically being one or two changes, and the first step requiring checking and moving nearly the entire list.\n",
    "\n",
    "Apparently dictionary operations are constant time, so O(1) time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_question": true,
    "problem": "Exercise B.1"
   },
   "source": [
    "### Exercise 1  \n",
    "\n",
    "Read the [Wikipedia page on Big-Oh notation](http://en.wikipedia.org/wiki/Big_O_notation) and answer the following questions:\n",
    "\n",
    " 1. What is the order of growth of n<sup>3</sup> + n<sup>2</sup>? What about 1000000 n<sup>3</sup> + n<sup>2</sup>? What about n<sup>3</sup> + 1000000 n<sup>2</sup>?\n",
    " 2. What is the order of growth of (n<sup>2</sup> + n) * (n + 1)? Before you start multiplying, remember that you only need the leading term.\n",
    " 3. If f is in O(g), for some unspecified function g, what can we say about af+b?\n",
    " 4. If f<sub>1</sub> and f<sub>2</sub> are in O(g), what can we say about f<sub>1</sub> + f<sub>2</sub>?\n",
    " 5. If f<sub>1</sub> is in O(g) and f<sub>2</sub> is in O(h), what can we say about f<sub>1</sub> + f<sub>2</sub>?\n",
    " 6. If f<sub>1</sub> is in O(g) and f<sub>2</sub> is O(h), what can we say about f<sub>1</sub> * f<sub>2</sub>? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "solution": "Exercise B.1"
   },
   "source": [
    "  1. O(n<sup>3</sup>), O(n<sup>3</sup>), O(n<sup>3</sup>)\n",
    "  2. O(n<sup>3</sup>)\n",
    "  3. The time for af + b would be the same as running the program at time f, a times, with an added b time portion.\n",
    "  4. f<sub>1</sub> + f<sub>2</sub> time would be the same as running the program when it takes time f<sub>1</sub>, then running it again when it takes time f<sub>2</sub>.\n",
    "  5. f<sub>1</sub> + f<sub>2</sub> time is the same as running the program with O(g) complexity for f<sub>1</sub> time, then running the O(h) program for f<sub>2</sub>.\n",
    "  6. f<sub>1</sub> * f<sub>2</sub> would be the same as nesting the O(h) complexity program within the O(g) one, then running the O(g) until time f<sub>1</sub>, and the O(h) until time f<sub>2</sub>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "poll_response": true,
    "solution": "Time spent"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_question": true,
    "problem": "Feedback"
   },
   "source": [
    "## Reading Journal feedback\n",
    "\n",
    "[Please complete this short survey](https://docs.google.com/forms/d/e/1FAIpQLScQekhUrf6YYjpfQiAAbavLIA-IJklv_PX1BWbGgxj7JPolmw/viewform?c=0&w=1)\n",
    "\n",
    "If you have any comments on this Reading Journal, feel free to leave them in the survey linked above. This could include suggestions to improve the exercises, topics you'd like to see covered in class next time, or other feedback.\n",
    "\n",
    "If you have Python questions or run into problems while completing the reading, you should post them to Piazza instead so you can get a quick response before your journal is submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "feedback_response": true,
    "solution": "Feedback"
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
